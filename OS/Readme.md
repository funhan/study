# 운영체제

컴퓨터의 하드웨어를 관리하고, 하드웨어와 소프트웨어, 사용자를 매개하는 프로그램이다.

# Process (프로세스)

프로세스는 실행 중인 프로그램으로 디스크로부터 메모리에 적재되어 CPU의 할당을 받을 수 있는 것을 말한다. 운영체제로부터 주소 공간, 파일, 메모리 등을 할당받으며 이것들을 총칭하여 프로세스라고 한다. 구체적으로 살펴보면 프로세스는 함수의 매개변수, 복귀 주소와 로컬 변수와 같은 임시자료를 갖는 프로세스 스택과 전역 변수들을 수록하는 데이터 섹션을 포함한다. 또한 프로세스는 프로세스 실행 중에 동적으로 할당되는 메모리인 힙을 포함한다.

## Process State

* new : 새로 생성된 상태
* ready :  프로세서에 할당되기를 기다리는 상태
* running : 프로세서에 할당되어 실행중인 상태
* waiting : 실행 중 작업이 완료되어 입출력(이벤트)이 생길 때까지 기다리는 상태
* terminated : 실행 종료된 상태

## Process Control Block (PCB, 프로세스 제어 블록)

PCB는 특정 프로세스에 대한 중요한 정보를 저장하고 있는 운영체제의 자료구조이다. 운영체제는 프로세스를 관리하기 위해 프로세스의 생성과 동시에 고유한 PCB를 생성한다. 프로세스는 CPU를 할당받아 작업을 처리하다가도 프로세스 전환이 발생하면 진행하던 작업을 저장하고 CPU를 반환해야 하는데, 이때 작업의 진행 상황을 모두 PCB에 저장하게 된다. 그리고 다시 CPU를 할당받게 되면 PCB에 저장되어있던 내용을 불러와 이전에 종료됐던 시점부터 다시 작업을 수행한다.


PCB에 저장되는 정보

* 프로세스 식별자(Process ID, PID) : 프로세스 식별번호
* 프로세스 상태 : new, ready, running, waiting, terminated 등의 상태를 저장
* 프로그램 카운터(Program Counter) : 프로세스가 다음에 실행할 명령어의 주소
* CPU 레지스터
* CPU 스케줄링 정보 : 프로세스의 우선순위, 스케줄 큐에 대한 포인터 등
* 메모리 관리 정보 : 페이지 테이블 또는 세그먼트 테이블 등과 같은 정보를 포함
* 입출력 상태 정보 : 프로세스에 할당된 입출력 장치들과 열린 파일 목록
* 어카운팅 정보 : 사용된 CPU 시간, 시간제한, 계정정보 등

## Context Switch

프로세스가 실행되다가 인터럽트가 발생해 운영체제가 개입하여 프로세서에 할당된 프로세스를 바꾸는 것을 말한다. 프로세서가 다른 프로세스로 스위치할 때, 시스템은 작업중이던 프로세스의 상태를 저장하고 새로운 프로세스의 상태를 로드한다. 프로세스 입장에서 컨텍스는 PCB이기 때문에 PCB 정보가 바뀌는 것을 컨텍스트 스위치라고 하는 것이다. 이는 오버헤드가 발생하는 작업이기 때문에 자주 일어나면 성능을 저하한다.

## Interprocess Communication (IPC)

프로세슷는 독립적으로 동작하거나 서로 협력하며 동작할 수 있다. 

### Message Passing

메모리 패싱은 우편이다. 송신 프로세스가 정보를 받는 수신 프로세스에게 커널을 통해 정보를 전달하며, 수신 프로세스도 커널에 접근해 정보를 수신한다. 메시지 패싱은 컨텍스트 스위치가 발생하기 때문에 속도는 느리지만 커널이 기본적인 기능을 제공하므로 공유 메모리 방식에 비해 구현이 쉽다.

### Shared Memory

공유 메모리는 게시판이다. 특정 메모리 공간을 두 프로세스가 함께 사용하며 정보를 주고 받는다. 커널을 거치지 않기 때문에 속도는 빠르지만 메모리에 동시 접근하는 것을 방지하기 위해 개발자가 따로 구현해야 한다.

### Sockets

소켓은 서버와 클라이언트가 통신하는 방식이다. IP 주소와 포트 정보가 있으면 클라이언트는 네트워크를 통해 서버 프로세스에 접근할 수 있다. RPC(Remote Procedure Calls)는 프로세스와 프로세스가 네트워크로 이어져 있을 때 발생하는 호출을 말한다. 서버와 클라이언트가 통신할 때는 IP 주소와 포트를 래핑해서 Stub으로 만들어 전송한다.


### Pipes

파이프는 부모 프로세스와 자식 프로세스가 통신할 때 사용하는 방식이다. 말 그대로 프로세스 사이에 파이프를 두고 정보를 주고 받는 것이다. 단 파이프는 단방향 통신만 가능하기 때문에 양방향으로 정보를 주고 받으려면 두 개의 파이프가 필요하다.   
파이프에 이름을 붙인 named pipe를 사용하면 꼭 부모-자식 관계가 아니더라도 파이프를 통해 통신할 수 있다.

</br>

# Thread (스레드)

스레드는 프로세스의 실행 단위라고 할 수 있다. 한 프로세스 내에서 동작되는 여러 실행 흐름으로 프로세스 내의 주소 공간이나 자원을 공유할 수 있다. 스레드는 스레드 ID, 프로그램 카운터, 레지스터 집합, 그리고 스택으로 구성된다. 같은 프로세스에 속한 다른 스레드와 코드, 데이터 섹션, 그리고 열린 파일이나 신호와 같은 운영체제 자원들을 공유한다. 하나의 프로세스를 다수의 실행 단위로 구분하여 자원을 공유하고 자원의 생성과 관리의 중복성을 최소화하여 수행 능력을 향상시키는 것을 멀티스레딩이라고 한다. 이 경우 각각의 스레드는 독립적인 작업을 수행해야 하기 때문에 각자의 스택과 PC 레지스터 값을 가지고 있다.

## 스택을 스레드마다 독립적으로 할당하는 이유

스택은 함수 호출 시 전달되는 인자, 되돌아갈 주소값 및 함수 내에서 선언하는 변수 등을 저장하기 위해 사용되는 메모리 공간이므로 스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능하다는 것이고, 이는 독립적인 실행 흐름이 추가되는 것이다. 따라서 스레드의 정의에 따라 독립적인 실행 흐름을 추가하기 위한 최소 조건으로 독립된 스택을 할당한다.

## PC Register를 스레드마다 독립적으로 할당하는 이유

PC 값은 스레드가 명령어의 어디까지 수행하였는지를 저장하고 있다. 스레드는 CPU를 할당받았다가 스케줄러에 의해 다시 선점당한다. 그렇기 때문에 명령어가 연속적으로 수행되지 못하고 어느 부분까지 수행했는지를 기억할 필요가 있다. 따라서 PC 레지스터를 독립적으로 할당한다.

</br>

# 멀티 스레딩

## 멀티 스레딩의 장점

프로세스를 이용하여 동시에 처리하던 일을 스레드로 구현할 경우 메모리 공간과 시스템 자원 소모가 줄어들게 된다. 스레드 간의 통신이 필요한 경우에도 별도의 자원을 이용하는 것이 아니라 전역 변수의 공간 또는 동적으로 할당된 공간인 힙 영역을 이용하여 데이터를 주고받을 수 있다. 그렇기 때문에 프로세스 간 통신 방법에 비해 스레드 간의 통신 방법이 훨씬 간단하다. 심시어 스레드의 context switch는 프로세스의 context switch와 달리 캐시 메모리를 비울 필요가 없기 때문에 더 빠르다. 따라서 시스템의 throughtput이 향상되고 자원 소모가 줄어들며 자연스럽 프로그램의 응답 시간이 단축된다. 이러한 장점 때문에 여러 프로세스로 할 수 있는 작업들을 하나의 프로세스에서 스레드로 나눠 수행하는 것이다.

## 멀티 스레딩의 문제점

멀티 프로세스 기반으로 프로그래밍할 때는 프로세스 간 공유하는 자원이 없기 때문에 동일한 자원에 동시에 접근하는 일이 없었지만 멀티 스레딩을 기반으로 프로그래밍할 때는 이 부분을 신경써줘야 한다. 서로 다른 스레드가 데이터와 힙 영역을 공유하기 때문에 어떤 스레드가 다른 스레드에서 사용중인 변수나 자료구조에 접근하여 엉뚱한 값을 읽어오거나 수정할 수 있다.

그렇기 때문에 멀티 스레딩 환경에서는 동기화 작업이 필요하다. 동기화를 통해 작업 처리 순서를 컨트롤하고 공유 자원에 대한 접근을 컨트롤하는 것이다. 하지만 이로 인해 병목현상이 발생하여 성능이 저하될 가능성이 높다. 그러므로 과도한 락으로 인한 병목현상을 줄여야 한다. 


## 멀티 스레드 vs 멀티 프로세스

멀티 스레드는 멀티 프로세스보다 적은 메모리 공간을 차지하고 문맥 전환이 빠르다는 장점이 있지만, 오류로 인해 하나의 스레드가 종료되면 전체 스레드가 종료될 수 있다는 점과 동기화 문제를 안고 있다. 반면 멀티 프로세스 방식은 하나의 프로세스가 죽더라도 다른 프로세스에는 영향을 끼치지 않고 정상적으로 수행된다는 장점이 있지만, 멀티 스레드보다 많은 메모리 공간과 CPU 시간을 차지한다는 단점이 존재한다. 이 두 가지는 동시에 여러 작업을 수행한다는 점에서 같지만 적용해야 하는 시스템에 따라 적합/부적합이 구분된다. 따라서 대상 시스템의 특징에 따라 적합한 동작 방식을 선택해야한다.


</br>

# 스케줄러

프로세스를 스케줄링하기 위한 Queue에는 세 가지 종류가 존재한다.

* Job Queue : 현재 시스템 내에 있는 모든 프로세스의 집합
* Ready Queue :  현재 메모리 내에 있으면서 CPU를 잡아서 실행되기를 기다리는 프로세스의 집합
* Device Queue : Device I/O 작업을 대기하고 있는 프로세스의 집합

각각의 Queue에 프로세스들을 넣고 빼주는 스케줄러에도 크게 세 가지 종류가 존재한다. 


## 장기 스케줄러 (Long-term Scheduler or Job Scheduler)

메모리는 한정되어 있는데 많은 프로세스들이 한꺼번에 메모리에 올라올 경우, 대용량 메모리(일반적으로 디스크)에 임시로 저장된다. 이 pool에 저장되어 있는 프로세스 중 어떤 프로세스에 메모리를 할당하여 ready queue로 보낼지 결정하는 역할을 한다.

* 메모리와 디스크 사이의 스케줄링을 담당 
* 프로세스에 메모리 및 각종 리소스를 할당(admit)
* degree of Multiprogramming 제어 (메모리에 여러 프로그램이 올라가는 것) 
  몇 개의 프로그램이 올라갈 것인지를 제어

* 프로세스의 상태
  new -> ready(in memory)

_cf) 메모리에 프로그램이 너무 많이 올라가도, 너무 적게 올라가도 성능이 좋지 않은 것이다. 참고로 time sharing system에서는 장기 스케줄러가 없다. 그냥 곧바로 메모리에 올라가 ready 상태가 된다._

</br>

## 단기 스케줄러 (Short-term Scheduler or CPU Scheduler)

* CPU와 메모리 사이의 스케줄링을 담당
* Ready Queue에 존재하는 프로세스 중 어떤 프로세스를 running 시킬지 결정
* 프로세스에 CPU를 할당 (schedule dispatch)
* 프로세스의 상태
  ready -> running -> waiting -> ready

</br>

## 중기 스케줄러 (Medium-term Scheduler or Swapper)

* 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아냄 (swapping)
* 프로세스에게서 메모리를 deallocate
* degree of Multiprogamming 제어
* 현 시스템에서 메모리에 너무 많은 프로그램이 동시에 올라가는 것을 조절하는 스케줄러
* 프로세스의 상태
  ready -> suspended

### Process state - suspended

Suspended(stopped) : 외부적인 이유로 프로세스의 수행이 정지된 상태로 메모리에서 내려간 상태를 의미한다. 프로세스 전부 디스크로 swap out된다. blocked 상태는 다른 I/O 작업을 기다리는 상태이기 때문에 스스로 ready state로 돌아갈 수 있지만, 이 상태는 외부적인 이유로 suspending 되었기 때문에 스스로 돌아갈 수 없다.


</br>


# CPU 스케줄러 (Short-term 스케줄러)

운영체제가 프로세스를 프로세서에 할당하는 것을 디스패치(Dispatch)라고 한다. (이때 프로세스의 상태 : ready -> running) 그리고 운영체제가 Ready Queue에 있는 프로세스들 중에서 어떤 프로세스를 디스패치할 것이나 정하는 것이 프로세스 스케줄링이다.

스케줄링 알고리즘에는 대표적으로 FCFS, SJF, SRF, RR 네 가지 방식이 있다. 
알고리즘을 평가할 때는 수행 시간(Burst time)과 CPU 사용량(CPU utilization), 단위 시간 당 끝마친 프로세스의 수(Throughput), 하나의 프로세스가 ready queue에서 대기한 시간부터 작업을 마칠 때까지 걸리는 시간(Turnaround time), 프로세스각 ready queue에서 대기한 시간(waiting time), 프로세스가 처음으로 CPU를 할당받기까지 걸린 시간(Response time)을 기준으로 한다. 

선점(Preemptive) 방식과 비선점(Non-Preemptive) 방식으로 나뉜다. 선점 스케줄링은 운영체제가 강제로 프로세스의 사용권을 통제하는 방식이고, 비선점 스케줄링은 프로세스가 스스로 다음 프로세스에게 자리를 넘겨주는 방식이다. 즉, 선점 스케줄링 방식에서는 CPU에 프로세스가 할당되어 있을 때도 운영체제가 개입해 다른 프로세스에게 CPU를 할당할 수 있다. 


## FCFS (First Come First Served)

* 먼저 들어온 프로세스를 먼저 프롯세서에 할당하는 방식이다. 즉, 먼저 온 순서대로 처리한다. 
* Queue의 FIFO와 동일하다.
* 프로세스 처리 순서에 따라 성능이 크게 달라질 수 있다.
* 먼저 온 프로세스가 끝날 때까지 운영체제가 개입하지 않는 `비선점 스케줄링 방식`이다.
* 수행 시간이 큰 프로세스가 먼저 들어오면 그 뒤에 들어온 프로세스들이 불필요하게 오랜 시간을 기다리게 되어 효율성을 낮추는 콘보이 효과(Convoy effect)가 발생한다.


## SJF (Shortest Job First)

* 다른 프로세스가 먼저 도착했어도 프로세스의 수행 시간이 짧은 순서에 따라 프로세서에 할당하는 방식이다.
* FCFS에서 발생하는 콘보이 효과를 해결할 수 있다.
* 수행 시간이 짧은 프로세스가 끝날 때까지 운영체제가 개입하지 않는 `비선점 스케줄링 방식`이다.
* 최적의 알고리즘이지만 수행 시간을 정확히 알 수 없다. (앞서 처리한 프로세스들의 기록을 보고 추측한다.)
* 수행 시간이 긴 프로세스는 계속 뒤로 밀려나는 기아(Starvation)가 발생한다.


## SRT (Shortest Remaining time First)


* 프로세스의 남은 수행 시간이 짧은 순서에 따라 프로세서에 할당하는 방식이다. 새로운 프로세스가 도착할 때마다 새로운 스케줄링이 이루어진다.
* 현재 수행중인 프로세스의 남은 수행 시간보다 더 짧은 수행 시간을 가지는 새로운 프로세스가 도착하면 운영체제가 개입해 자리를 바꾸는 `선점 스케줄링 방식`이다.
* 선점을 위한 context switch의 오버헤드가 크다.
* 새로운 프로세스가 도착할 때마다 스케줄링을 다시하기 때문에 각 프로세스들의 실행 시간을 추적하기 힘들다. 
* 수행 시간이 긴 프로세스는 SJF보다 대기 시간이 더 길어 기아 문제가 발생한다. 


## Priority Scheduling

* 특정 기준으로 프로세스에게 우선순위를 부여해 우선순위에 따라 프로세서에 할당하는 방식이다.
* 선점 스케줄링 방식
  더 높은 우선순위의 프로세스가 도착하면 실행중인 프로세스를 멈추고 CPU를 선점한다.
* 비선점 스케줄링 방식
  더 높은 우선순위의 프로세스가 도착하면 Ready Queue의 맨 앞에 넣는다.
* SRF의 경우 남은 수행 시간을 기준으로 우선순위를 부여한다고 볼 수 있다.
* 우선순위가 낮은 프로세스는 계속 밀리는 기아 문제가 발생한다. (== 실행 준비는 되었으나 CPU를 사용하지 못하는 프로세스를 CPU를 기다리며 봉쇄된 것으로 간주되는 무기한 봉쇄(Indefinite blocking) 문제가 발생한다.)
  이를 해결하기 위해, 우선순위가 낮은 프로세스라도 오래 기다리면 우선순위를 높여주는 Aging을 한다.


## RR (Round Robin)

* 현대적인 CPU 스케줄링이다.
* 각 프로세스는 동일한 크기의 할당 시간(time quantum)을 갖게 된다.
* 할당 시간이 지나면 프로세스는 선점당하고 ready queue의 제일 뒤에 가서 다시 기다린다.
* RR은 CPU 사용 시간이 랜덤한 프로세스들이 섞여있을 경우에 효율적이다.
* RR이 가능한 이유는 프로세스의 context를 저장할 수 있기 때문이다.
* Response time이 빨라진다.
  n개의 프로세스가 ready queue에 있고 할당 시간이 q(time quantum)인 경우 각 프로세스는 q 단위로 CPU 시간의 1/n을 얻는다. 즉, 어떤 프로세스도 (n-1)q time unit 이상 기다리지 않는다.
* 프로세스가 기다리는 시간이 CPU를 사용할 만큼 증가한다. 공정한 스케줄링이라고 할 수 있다.
* 시간 할당량에 따라 운영체제가 계속 개입하는 `선점 스케줄링 방식`이다.
* 주의할점은 설정한 time quantum이 너무 커지면 FCFS와 같아진다. 또 너무 작아지면 스케줄링 알고리즘의 목적에는 이상적이지만 잦은 context switch로 오버헤드가 발생한다. 따라서 적당한 time quantum을 설정하는 것이 중요하다.



# 동기와 비동기

## 비유를 통한 쉬운 설명

해야할 일(task)가 빨래, 설거지, 청소 세 가지가 있다고 가정한다. 이 일들을 동기적으로 처리한다면 빨래를 하고 설거지를 하고 청소를 한다. 비동기적으로 일을 처리한다면 빨래하는 업체에게 빨래를 시킨다. 설거지 대행 업체에 설거지를 시킨다. 청소 대행 업체에 청소를 시킨다. 셋 중 어떤 것이 먼저 완료될지는 알 수 없다. 일을 모두 마친 업체는 나에게 알려주기로 했으니 나는 다른 작업을 할 수 있다. 이 때는 백그라운드 스레드에서 해당 작어블 처리하는 경우의 비동기를 의미한다.

## Sync v Async

일반적으로 동기와 비동기의 차이는 메소드를 실행시킴과 `동시에` 반환 값이 기대되는 경우를 `동기`라고 표현하고 그렇지 않은 경우에 대해서 `비동기`라고 표현한다. 동시에 라는 말은 실행되었을 때 값이 반환되기 전까지는 `blocking`되어 있다는 것을 의미한다. 비동기의 경우, `blocking`되지 않고 이벤트 큐에 넣거나 백그라운드 스레드에게 해당 task를 위임하고 바로 다음 코드를 실행하기 때문에 기대되는 값이 바로 반환되지 않는다.

### Reference

* http://asfirstalwys.tistory.com/348


# 프로세스 동기화

## Race condition 

만약 두 프로세스가 동시에 어떤 변수의 값을 바꾼다면 프로그래머의 의도와는 다른 결과가 나올 것이다. 이처럼 프로세스가 어떤 순서로 데이터에 접근하느냐에 따라 결과 값이 달라질 수 있는 상황을 `경쟁 상태`라고 한다.

## Critical Section (임계 영역)

멀티 스레딩에 문제점에서 나오듯, 동일한 자원을 동시에 접근하는 작업(e.g. 공유하는 변수 사용, 동일 파일을 사용하는 등)을 실행하는 코드 영역을 Critical Section이라 한다. 

## Critical Section Problem (임계 영역 문제)

프로세스들이 Ciritical Section을 Race condition이 발생하지 않고 함께 사용할 수 있는 프로토콜을 설계하는 것이다.

### Requirements (해결을 위한 기본조건)

* Mutual Exclusion (상호 배제)
  프로세스 P1이 Critical Section에서 실행중이라면, 다른 프로세스들은
그들이 가진 Critical Section에 진입해서는 안된다. 

* Progress (진행)
  Critical Section에서 실행중인 프로세스가 없고, 별도의 동작이 없는 프로세스들만 Critical Section 진입 후보로서 참여될 수 있다.

* Bounded Waiting (한정된 대기)
  프로세스 P1이 Critical Section에 진입 신청 후부터 받아들여질 때까지, 다른 프로세스들이 Critical Section에 진입하는 횟수는 제한이 있어야 한다. 즉, Starvation 문제를 방지해야 한다.


## 해결책

### Peterson’s Solution

임계 영역에서 프로세스가 작업중인지 저장하는 변수 `flag`와 critical section에 진입하고자하는 프로세스를 가리키는 변수 `turn`을 만들어 어떤 프로세스가 임계 영역에 진입하면 `flag`를 `lock`하고, 나오면 `unlock`하는 방식으로 임계 영역 문제를 해결한다.

``` 
do {
	flag[i] = true;
	turn = j;
	while (flag[j] && turn == j);
	// Critical Section
	flag[i] = false;
	// Remainder Section
} while(true);

```


### Mutex Lock 

* 동시에 공유 자원에 접근하는 것을 막기 위해 Critical Section에 진입하는 프로세스는 Lock을 획득하고 Critical Section을 빠져나올 때, Lock을 방출함으로써 동시에 접근이 되지 않도록 한다.

* 한계
  다중처리기 환경에서는 시간적인 효율성 측면을 적용할 수 없다.


### Semaphores (세마포어)

* 여러 개의 프로세스나 스레드가 critical section에 진입할 수 있는 locking 매커니즘이다. 세마포어는 카운터를 이용해 동시에 리소스에 접근할 수 있는 프로세스를 제한한다. 물론 한 프로세스가 값을 변경할 때 다른 프로세스가 동시에 값을 변경하지는 못한다.


#### 종류

* Binary Semaphore (이진 세마포어)
  Mutex라고도 부르며, 상호배제(Mutual Exclusion)의 머릿글자를 따서 만들어졌다. 이름 그대로 0과 1 사이의 값만 가능하며, 다중 프로세스들 사이의 Critical Section 문제를 해결하기 위해 사용한다. 

* Counting Semaphore (카운팅 세포어)
  가용한 개수를 가진 자원에 대한 접근 제어용으로 사용되며, 세마포어는 그 가용한 자원의 개수로 초기화된다. 자원을 사용하면 세모포어 감소, 방출하면 증가한다. 

#### 단점

* Busy Waiting (바쁜 대기)
  Critical Section에 진입해야 하는 프로세스는 진입 코드를 계속 반복 실행해야 하므로, CPU 자원을 낭비하게 된다. 이를 해결하기 위해 지속적(while)로 확인하는 것이 아닌 block()과 wakeup()을 사용해 대기 큐에 넣고 후에 다시 시작한다. 임계 구역이 짧으면 busy waiting을, 길면 block&wakeup 방식을 사용한다.


#### Deadlock and Starvation

세마포어의 문제점으로 두 개가 있다.

##### Deadlock (교착상태)
* 둘 이상의 프로세스들이 자원을 점유한 상태에서 서로 다른 프로세스가 점유하고 있는 자원을 요구하며 무한정 기다리는 형상을 의미한다. 

* Dining-Philosophers Problem (철학작들의 만찬 문제)
  철학자 5명이 식탁 가운데 음식을 두고 철학자들은 사색과 식사를 반복한다. 포크는 총 5개, 단 음식을 먹으려면 2개의 포크를 사용해야 한다. 즉, 동시에 음식을 먹을 수 있는 사람은 두명 뿐이다. 운이 좋으면 5명의 철학자들이 돌아가면서 사색과 식사를 이어갈 수 있다. 하지만 모두가 포크를 하나씩 들고 식사를 하려하면 누구도 식사를 할 수 없는 상태, 다시말해 데드락에 빠져버린다.

##### Starvation (기아문제)
* 하나의 프로세스가 실행되지 못하고 무한정 기다리는 상태를 말한다. 이는 프로세스가 임계구역을 기다릴 때 대기 큐에 들어가기 때문에 발생한다.


### Monitor (모니터)

* 고급 언어의 설계 구조물로서, 개발자의 코드를 상호배제 하게끔 만든 추상화된 데이터 형태이다.

* 공유 자원에 접근하기 위한 키 획득과 자원 사용 후 해제를 모두 처리한다. (세마포어는 직접 키 해제와 공유 자원 접근 처리가 필요하다.)




























