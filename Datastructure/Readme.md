# Datastructure

* [선형구조]
  * Array
  * Linked list
  * Stack
  * Queue
  
* [비선형구조]
  * Tree
  * Graph
  
</br>

## Array vs LinkedList

### Array

가장 기본적인 자료구조인 `Array`는 논리적 저장 순서와 물리적 저장 순서가 일치한다. 따라서 인덱스로 해당 원소에 접근이 가능하다. 그렇기 때문에 찾고자 하는 원소의 인덱스 값을 알고 있으면 `O(1)`만에 해당 원소로 접근할 수 있다. 즉, Random Access가 가능하다.
   
하지만 삭제 또는 삽입 과정에서 해당 원소에 접근하여 작업을 완료한 뒤(`O(1)`), Shift를 해주는 작업을 추가적으로 해줘야 하기 때문에, 시간이 더 걸린다. 만약 배열의 원소 중 어느 원소를 삭제했다고 했을 때, 배열의 연속적인 특징이 깨지게 된다. 즉 빈 공간이 생기는 것이다. 따라서 삭제한 원소보다 큰 인덱스를 갖는 원소들을 Shift해줘야 하는 비용(Cost)이 발생하고 이 경우의 시간 복잡도는 `O(n)`이 된다. 그렇기 때문에 Array 자료구조에서 삭제  기능에 대한 시간복잡도의 worst case는 `O(n)`이 된다. 삽입의 경우도 마찬가지이다. 만약 첫번째 자리에 새로운 원소를 추가하고자 한다면, 모든 원소들의 인덱스를 1씩 Shift해줘야 하므로 이 경우도 `O(n)`의 시간복잡도를 가진다.
   
### LinkedList

`Array`의 문제점을 해결하기 위한 자료구조이다. `LinkedList`는 자료의 주소 값으로 노드를 이용해 서로 연결되어 있는 구조를 갖는다. 각각의 원소들은 자기 자신 다음에 어떤 원소인지만을 기억하고 있다. 따라서 이 부분만 다른 값으로 바꿔주면 삭제와 삽입을 `O(1)`만에 수행할 수 있다.

하지만 원하는 위치에 삽입을 하고자 한다면, 원하는 위치를 `Search`하는 과정에 있어서 첫번째 원소부터 일일이 확인해봐야 한다. Array와 달리 논리적 저장 순서와 물리적 저장 순서가 일치하지 않기 때문이다. 따라서 어떤 원소를 삭제 또는 삽입할 때, 그 원소를 찾기 위해서 `O(n)`의 시간이 추가적으로 발생하게 된다.

따라서 LinkedList는 탐색, 삽입, 삭제에 대해서 `O(n)`의 시간복잡도는 갖는다. 하지만 이 자료구조는 `Tree` 구조의 근간이 되는 자료구조이므로 중요하다.

#### 결론

데이터 접근 속도는 Array가 Random Access가 가능하므로 `O(1)`이고, LinkedList는 순차 접근으로 `O(n)`이다. 따라서 Array가 LinkedList보다 더 빠르다.

데이터 삽입 속도는 Array, LinkedList 모두 `O(n)`이지만, Array의 경우 삽입하기 위해 데이터를 Shift하는 과정이 필요하므로 데이터가 많을 경우 비효율적이다. LinkedList는 삽입할 위치를 찾고(`O(n)`) 삽입을 하기 때문에, Array보다 빠르다. 삭제의 경우도 동일하다.

따라서 삽입/삭제가 빈번하다면 LinkedList를 사용하는 것이 좋고, 데이터의 접근이 중요하다면 Array를 사용하는 것이 좋다.

</br>

## Stack, Queue

### Stack

`Last In First Out (LIFO)`. 즉, 나중에 들어간 원소가 먼저 나오는 구조이다. 차곡차곡 쌓이는 구조로 먼저 Stack에 들어가게 된 원소는 맨 바닥에 깔리게 된다. 그렇기 때문에 늦게 들어간 원소는 그 위에 쌓이게 되고 호출 시 가장 위에 있는 원소가 호출되는 구조이다.

### Queue

`First In First Out (FIFO)`. 즉, 먼저 들어간 원소가 먼저 나오는 구조이다. Stack과는 반대로 먼저 들어간 원소가 맨 앞에서 대기하고 있다가 먼저 나오게 되는 구조이다. 

</br>

## Tree

Tree는 비선형 자료구조이며, 계층적 관계(Hierarchical Relationship)을 표현하는 자료구조이다. 

#### Tree를 구성하고 있는 구성요소들

* Node (노드) : 트리를 구성하고 있는 각각의 요소를 의미한다.
* Edge (간선) : 트리를 구성하기 위해 노드와 노드를 연결하는 선을 의미한다.
* Root Node (루트 노드) : 트리 구조에서 최상위에 있는 노드를 의미한다.
* Leaf Node ( = Terminal Node, 단말 노드) : 하위에 다른 노드가 연결되어 있지 않은 노드를 의미한다.
* Internal Node (내부노드, 비단말 노드) : 단말 노드를 제외한 모든 노드로 루트 노드를 포함한다.

트리의 속성 중 가장 중요한 것은 루트 노드를 제외한 모든 노드는 단 하나의 부모 노드만을 가진다는 것이다. 이 속성 때문에 트리는 다음의 성질을 만족한다.

* 임의의 노드에서 다른 노드로 가능 경로(path)는 유일하다.
* cycle이 존재하지 않는다.
* 모든 노드는 서로 연결되어 있다.
* Edge의 수(E) = 노드의 수(V) - 1


</br>

### Binary Tree (이진 트리)

루트 노드를 중심으로 두 개의 서브 트리(큰 트리에 속하는 작은 트리)로 나뉘어 진다. 또한 나뉘어진 두 서브 트리도 모두 이진 트리여야 한다. 즉, 각 노드가 자식을 최대 2개를 가지는 트리를 의미한다. 재귀적인 정의라 맞는듯 하면서도 이해가 쉽지 않다. 덧붙이자면 공집합도 이진 트리로 포함시켜야 한다. 그래야 재귀적으로 조건을 확인해갔을 때, leaf node에 다 달았을 때 정의가 만족하기 때문이다.

트리에서는 각 층 별로 숫자를 매겨서 이를 트리의 `Level`이라고 한다. Level의 값은 0 부터 시작하고 따라서 루트 노드의 레벨은 0 이다. 그리고 트리의 최고 Level을 가리켜 해당 트리의 `height`라고 한다.

#### Binary Tree 순회 방법

* 전위 순회 (Preorder) : 루트 -> 왼쪽 -> 오른쪽
* 중위 순회 (Inorder) : 왼쪽 -> 루트 -> 오른쪽
* 후위 순회 (Postorder) : 왼쪽 -> 오른쪽 -> 루트

#### Skewed Binary Tree (편향 이진 트리)

루트 노트를 제외한 모든 노드가 부모 노드의 왼쪽 노드이거나 오른쪽 노드로 편향되어 있는 이진 트리

#### Full Binary Tree (포화 이진 트리)

모든 레벨에서 노드들이 꽉 채워진 이진 트리

#### Complete Binary Tree (왼전 이진 트리)

위에서 아래로, 왼쪽에서 오른쪽으로 순서대로 차곡차곡 채워진 이진 트리

배열로 구성된 Full Binary Tree와 Complete Binary Tree는 노드의 개수가 n개 일 때, i번째 노드에 대해서 parent(i) = i/2, left child(i) = 2i, right child(i) = 2i + 1의 인덱스 값을 갖는다.

</br>

### BST (Binary Search Tree, 이진 탐색 트리)

효율적인 탐색을 위한 저장 방법이 무엇일까를 고민해야 한다. 이진 탐색 트리는 이진 트리의 일종이다. 단, 이진 탐색 트리에는 데이터를 저장하는 규칙이 있다. 그리고 그 규칙은 특정 데이터의 위치를 찾는데 사용할 수 있다.

* 규칙 1. 이진 탐색 트리의 노드에 저장된 키는 유일하다.
* 규칙 2. 루트 노드의 키가 왼쪽 서브 트리를 구성하는 어떠한 노드의 키보다 크다.
* 규칙 3. 루트 노드의 키가 오른쪽 서브 트리를 구성하는 어떠한 노드의 키보다 작다.
* 규칙 4. 왼쪽과 오른쪽 서브 트리도 이진 탐색 트리이다.

이진 탐색 트리의 탐색 연산은 `O(log n)`의 시간 복잡도를 갖는다. 사실 정확히 말하면 `O(h)`라고 표현하는 것이 맞다. 트리의 높이를 하나씩 더해갈수록 추가할 수 있는 노드의 수가 두 배씩 증가하기 때문이다. 하지만 이러한 이진 탐색 트리는 편향 트리가 될 수 있다. 저장 순서에 따라 계속 한 쪽으로만 노드가 추가되는 경우가 발생하기 때문이다. 이럴 경우 성능에 영향을 미치게 되며, 탐색의 worst case가 되고 시간 복잡도는 `O(n)`이 된다.

배열보다 많은 메모리를 사용하여 데이터를 저장했지만 탐색에 필요한 시간 복잡도가 같게 되는 비효율적인 상황이 발생한다. 이를 해결하기 위해 `Rebalancing` 기법이 등장하였다. 균형을 잡기 위한 트리 구조의 재조정을 `Rebalancing`이라 한다. 이 기법을 구현한 트리에는 여러 종류가 존재하는데 그 중에서 하나가 `Red-Black Tree`이다.

</br>

### Heap

Tree의 형식을 하고 있으며, Tree 중에서도 배열에 기반한 Complete Binary Tree이다. 배열에 트리의 값들을 넣어줄 때, 0번째는 건너뛰고 1번 인덱스부터 루트 노드가 시작된다. 이는 노드의 고유 번호 값과 배열의 인덱스를 일치시켜 혼동을 줄이기 위함니다. Heap에는 max heap (최대힙)과 min heap (최소힙) 두 종류가 있다.


#### Max Heap, Min Heap

`Max Heap`은 각 노드의 값이 해당 Children 의 값보다 크거나 같은 Complete Binary Tree를 말한다. ( `Min Heap`은 그 반대이다.)

`Max Heap`에서는 루트 노드에 있는 값이 제일 크므로, 최대값을 찾는데 소요되는 연산의 시간 복잡도는 `O(1)`이다. 그리고 Complete Binary Tree이기 때문에 배열을 사용하여 효율적으로 관리할 수 있다. (즉, Random Access가 가능하다.) `Min Heap`에서는 최소값을 찾는데 소요되는 연산의 시간 복잡도는 `O(1)`이다. 하지만 Heap의 구조를 계속 유지하기 위해서는 제거된 루트 노드를 대체할 다른 노드가 필요하다. 여기서 Heap은 맨 마지막 노드를 루트 노드로 대체시킨 후, 다시 `Heapify` 과정을 거쳐 Heap 구조를 유지한다. 이러한 경우에는 결국 `O(log n)`의 시간 복잡도로 최대값 또는 최소값에 접근할 수 있다.

#### Heapify

두 개의 서브 트리가 max heap이라고 가정할 때, 루트에 추가된 노드를 포함한 전체가 heap을 만족하도록 각 노드들의 위치를 조정하는 과정을 말한다. min heap인 경우에도 마찬가지로 적용된다. max heap의 경우에는 루트에서 작은 값이, min heap의 경우에는 큰 값이 트리 구조를 따라 흘러내려가면서 처리되는 방식으로 진행된다.

max heapify는 루트 노드의 값이 자식 노드의 값보다 작으면, 두 개의 자식 노드 중 값이 큰 노드와 루트 노드를 교체하고, 이 과정을 교체할 노드가 없을 때까지 반복해준다. 이와 마찬가지로 min heapify는 루트 노드의 값이 자식 노드의 값보다 크면, 두 개의 자식 노드 중 값이 작은 노드와 루트 노드를 교체하고, 이 과정을 교체할 노드가 없을 때까지 반복해준다. 

</br>

### Map 


</br>

### Set


</br>


### Red-Black Tree 

RBT(Red-Blackc Tree)는 BST를 기반으로 한 트리 형식의 자료구조이다. 결론부터 말하자면 Red-Black Tree에 데이터를 저장하게 되면 Search, Insert, Delete에 `O(log n)`의 시간 복잡도가 소요된다. 동일한 노드의 개수일 때, depth를 최소화하여 시간 복잡도를 줄이는 것이 핵심 아이디어이다. 동일한 노드의 개수일 때, depth가 최소가 되는 경우는 트리가 Complete Binary Tree인 경우이다.


#### Red-Black Tree의 정의

RBT는 다음의 성질을 만족하는 BST이다.

* 각 노드는 `Red` 또는 `Black`이라는 색깔을 갖는다.
* 루트 노드의 색깔을 `Black`이다.
* 각 리프 노드는 `Black`이다.
* 어떤 노드의 색깔이 `Red`이면 두 개의 children의 색깔은 모두 `Black`이다. ( = No Double Red, 빨간색 노드가 연속으로 나올 수 없다.)
* 각 노드에 대해서 노드로부터 descendant leaves까지의 단순 경로는 모두 같은 수의 Black 노드들을 포함하고 있다. 이를 해당 노드의 `Black-Height`라고 한다. ( Black-Height : 노드 x로부터 노드 x를 포함하지 않은 리프 노드까지의 simple path 상에 있는 black 노드들의 개수 )

#### Red-Black Tree의 특징

* Binary Search Tree이므로 BST의 특징을 모두 갖는다.
* 루트 노드부터 리프 노드까지의 모든 경로 중 최소 경로와 최대 경로의 크기 비율은 2보다 크지 않다. 이러한 상태를 `Balanced` 상태라고 한다.
* 노드의 자식이 없을 경우 자식을 가리키는 포인터는 NIL 값을 저장한다. 이러한 NIL 들을 리프 노드로 간주한다.

#### 삽입

우선 BST의 특성을 유지하면서 노드를 삽입한다. 그리고 삽입된 노드의 색깔을 `Red`로 지정한다. `Red`로 지정하는 이유는 Black-Height 변경을 최소화하기 위함이다. 삽입 결과 RBT의 특성에 위배(violation)시 노드의 색깔을 조정하고, Black-Height가 위배되었다면 rotation을 통해 Height를 조정한다. 이러한 과정을 통해 RBT의 동일한 Height에 존재하는 internal node들의 Black-Height가 같아지게 되고 최소 경로와 최대 경로의 크기 비율이 2 미만으로 유지된다. 

1. BST의 삽입을 수행한다.
2. 삽입한 노드를 `Red`로 한다.
3. 만약 삽입한 노드의 부모가 `Black`이면, 삽입 끝.
4. 만약 삽입한 노드의 부모가 `Red`이면, 다음과 같은 동작 수행. 이때, 부모 노드가 조부 노드의 왼쪽 자식일 경우이다. 오른쪽 자식인 경우는 왼쪽 자식의 경우의 반대로 수행하면 된다.
    
    4.1 삼촌 노드가 `Red`인 경우, 부모 노드와 삼촌 노드를 `Black`으로 하고 조부 노드를 `Red`로 한다. 이 과정을 수행한 후, 조부 노드를 현재 노드로 설정하고 특성에 위배되는 게 없는지 루트 노드에 도달할 때까지 반복한다.
    
    4.2 삼촌 노드가 `Black`이고 삽입한 노드가 부모 노드의 오른쪽 자식일 경우, 부모 노드를 왼쪽으로 Rotation 시킨다. 이 후 4.3으로 이동한다.
    
    4.3 삼촌 노드가 `Black`이고 삽입한 노드가 부모 노드의 왼쪽 자식일 경우, 부모 노드를 `Black`으로 조부 노드를 `Red`로 하고 조부 노드를 오른쪽으로 Rotation 시킨다.
 

삽입의 경우 삽입하는 위치를 찾는데 `O(log n)`이 걸리게 된다. 

4.1의 경우를 `O(1)`이 걸리지만, 루트 노드까지 도달할 수 있으므로 최악의 경우 `O(log n)`이 걸리고 총 `O(log n)`이 걸린다.

4.2, 4.3의 경우 `O(1)`이 걸리고, 총 `O(log n)`이 걸린다. 따라서 삽입 연산은 `O(log n)`이 걸린다.


#### 삭제

삭제도 삽입과 마찬가지로 BST의 특성을 유지하면서 해당 노드를 삭제한다. 삭제될 노드의 child의 개수에 따라 rotation 방법이 달라지게 된다. 그리고 만약 지워진 노드의 색깔이 `Black`이라면 Black-Height가 1 감소한 경로에 black 노드가 1개 추가되도록 rotation을 하고 노드의 색깔을 조정한다. 지워진 노드의 색깔이 `Red`라면 위배가 발생하지 않으므로 RBT가 그대로 유지된다.

1. BST의 삭제를 수행한다.
2. 만약 삭제된 노드가 `Red`이면, 삭제 끝.
3. 만약 삭제된 노드가 `Black`이면, 삭제된 노드를 대체하는 노드를 `Black`으로 한다. 대체하는 노드가 `Black`이었다면, 이중흑색노드가 발생한다. 다음과 같은 동작 수행. 이때, 이중흑색노드가 부모 노드의 왼쪽 자식일 경우이다. 오른쪽 자식인 경우는 왼쪽 자식의 경우의 반대로 수행하면 된다.

    3.1 이중흑색노드의 형제 노드가 `Red`일 경우, 형제 노드를 `Black`, 부모 노드를 `Red`로 하고, 부모 노드를 기준으로 왼쪽으로 Rotation 시킨다. 이를 수행해도 여전히 이중흑색노드이며, 형제 노드는 `Black`이 된다. 이후 2, 3, 4 Case로 넘어가게 된다. 
    
    3.2 이중흑색노드의 형제가 `Black`이고 형제의 양쪽 자식 모두 `Black`일 경우, 형제 노드를 `Red`로 하고, 이중흑색노드의 `extra Black`을 부모 노드로 전달한다. 이때, 부모 노드가 `Red`였으면, `Black`으로 하고 끝낸다. 만약 `Black`이었다면, 부모 노드가 이중흑색노드가 되고, 위배가 발생하지 않을 때까지 3을 반복한다.
    
    3.3 이중흑색노드의 형제가 `Black`이고 형제의 왼쪽 자식이 `Red`일 경우, 형제 노드를 `Red`로 하고 형제 노드의 왼쪽 자식을 `Black`으로 한다. 그리고 형제 노드를 기준으로 오른쪽으로 Rotation을 시킨다. 이때, 형제 노드의 오른쪽 자식이 `Red`가 되고, 이는 3.4이 경우로 넘어간다.
    
    3.4 이중흑색노드의 형제가 `Black`이고 형제의 오른쪽 자식이 `Red`일 경우, 부모 노드의 색을 형제 노드의 색으로 한다. 그리고 부모 노드와 형제 노드의 오른쪽 자식을 `Black`으로 하고, 부모 노드를 기준으로 왼쪽으로 Rotation을 수행한다.



#### AVL Tree vs Red-Black Tree

* AVL이 더 엄격한 Balanced를 유지하고 있어 Search가 더빠르다.
* RBT가 더 느슨한 Balanced를 유지하고 있어 삽입과 삭제가 더 빠르다.
* RBT가 AVL보다 색깔을 저장하기 위해 더 많은 공간을 사용한다.

 
#### reference
https://ict-nroo.tistory.com/73

</br>


## HashTable

`hash`는 내부적으로 배열을 사용하여 데이터를 저장하기 때문에 빠른 검색 속도를 가진다. 특정한 값을 탐색하는데 데이터 고유의 인덱스로 접근하게 되므로 average case에 대하여 시간 복잡도가 `O(1)`이 되는 것이다.( 항상 `O(1)`이 아니고 average case에 대해서 `O(1)`인 것인 collision 때문이다.) 하지만 문제는 이 인덱스로 저장되는 key 값이 불규칙하다는 것이다.

그래서 특별한 알고리즘을 이용하여 저장할 데이터와 연관된 고유한 숫자를 만들어 낸 뒤 이를 인덱스로 사용한다. 특정 데이터가 저장되는 인덱스는 그 데이터만의 고유한 위치이기 때문에, 삽입 연산 시 다른  데이터의 사이에 끼어들거나, 삭제 시 다른 데이터로 채울 필요가 없으므로 연산에서 추가적인 비용이 없도록 만들어진 자료구조이다.


### hash function

특별한 알고리즘이란 것을 통해 고유한 인덱스 값을 설정하는 것이 중요하다. 특별한 알고리즘을 `hash function (해시 함수)`라고 하고, 이 함수에 의해 반환된 데이터의 고유 숫자 값을 `hashcode`라고 한다. 저장되는 값들의 key 값을 `hash function`을 통해서 작은 범위의 값들로 바꾸어준다. 

하지만 어설픈 `hash function`을 통해서 key 값들을 결정한다면 동일한 값이 도출될 수 있다. 이렇게 되면 동일한 key 값에 복수 개의 데이터가 하나의 테이블에 존재할 수 있게 되는데 이를 `Collision`이라고 한다.

#### hash function의 조건

일반적으로 좋은 `hash function`는 key의 일부분을 참조하여 해쉬 값을 만들지 않고 키 전체를 참조하여 해쉬 값을 만들어 낸다. 하지만 좋은 해쉬 함수는 키가 어떤 특성을 가지고 있느냐에 따라 달라지게 된다.

`hash function`를 무조건 1:1로 만드는 것보다 Collision을 최소화하는 방향으로 설계하고 발생하는 Collision에 대비해 어떻게 대응할 것인가가 더 중요하다. 1:1 대응이 되도록 만드는 것이 거의 불가능하기도 하지만 그런 `hash function`를 만들어봤자 Array와 다를바 없고 메모리를 너무 차지하게 된다.

Collision이 많아질수록 탐색에 필요한 시간 복잡도는 `O(1)`에서 `O(n)`에 가까워진다. 어설픈 `hash function`는 hash를 hash 답게 사용하지 못하도록 한다. 좋은 `hash function`를 선택하는 것은 hash table의 성능 향상에 필수적인 것이다.

따라서 hashing된 인덱스에 이미 다른 값이 들어 있다면 새로운 데이터를 저장할 다른 위치를 찾은 뒤에야 저장할 수 있는 것이다. 아래는 충돌이 발생했을 시 해결 방법이다.


### Resolve Conflict

#### 1. Open Address 방식 (개방 주소법)

해시 충돌이 발생하면, 다른 해시 버킷에 해당 자료를 삽입하는 방식이다. 버킷이란 데이터를 저장하기 위한 공간이다.

공개 주소 방식이라고 불리는 이 알고리즘은 충돌이 발생하면 데이터를 저장할 장소를 찾는다. Worst Case의 경우 비어있는 버킷을 찾지 못하고 탐색을 시작한 위치까지 되돌아 올 수 있다. 이 방법은 다음과 같이 3가지가 있다.

* Linear Probing (선형탐색)

순차적으로 탐색하며 비어있는 버킷을 찾을 때까지 진행한다. ( 다음 해시(+1)나 n개를 건너뛴 해시에 데이터를 저장)
    
* Quadratic Probing (제곱탐색)

2차 함수를 이용해 탐색할 위치를 찾는다. 
    
* Double hashing Probing

하나의 해쉬 함수에서 충돌이 발생하면 2차 해쉬 함수를 이용해 새로운 주소를 할당한다. 위 두 방법에 비해 많은 연산량을 요구한다.


#### 2. Separate Chaining 방식 (분리 연결법)

일반적으로 Open Addressing은 Separate Chaining보다 느리다. Open Addressing의 경우 해시 버킷을 채운 밀도가 높아질수록 Worst Case 발생 빈도가 더 높아지기 때문이다. 반면 Separate Chaining 방식의 경우 해시 충돌이 잘 발생하지 않도록 보조 해시 함수를 통해 조정할 수 있다면 Worst Case 에 가까워 지는 빈도를 줄일 수 있다. Java 7에서는 Separate Chaining 방식을 사용하여 HashMap을 구현하고 있다. Separate Chaining 방식은 두 가지 구현 방식이 존재한다.

* 연결 리스트를 사용하는 방식 (LinkedList)

각각의 버킷들을 연결리스트로 만들어 충돌이 발생하면 해당 버킷의 리스트에 추가하는 방식이다. 연결리스트의 특징을 그대로 이어받아 삭제 또는 삽입이 간단하다. 하지만 단점도 그대로 물려받아 작은 데이터들을 저장할 때 연결리스트 자체의 오버헤드가 부담이 된다. 또 다른 특징으로는, 버킷을 계속해서 사용하는 Open Address 방식에 비해 테이블의 확장을 늦출 수 있다. 

* 트리를 사용하는 방식 (Red-Black Tree)

기본적인 알고리즘은 Separate Chaining 방식과 동일하며 연결리스트 대신 트리를 사용하는 방식이다. 연결리스트를 사용할 것인가와 트리를 사용할 것인가에 대한 기준은 하나의 해시 버킷에 할당된 key-value 쌍의 개수이다. 데이터의 개수가 적다면 연결리스트를 사용하는 것이 좋다. 트리는 기본적으로 메모리 사용량이 많기 때문이다. 데이터 개수가 적을 때 Worst Case를 살펴보면 트리와 연결리스트의 성능 상 차이가 거의 없다. 따라서 메모리 측면으로 봤을 때 데이터 개수가 적다면 연결리스트를 사용한다. 

#### 데이터가 적다는 것은 얼마나 적다는 것을 의미하나?

앞에서 말했듯이 기준은 하나의 해시 버킷에 할당된 key-value 쌍의 개수이다. 이 key-value 쌍의 개수가 6개, 8개를 기준으로 결정한다. 이는 연결리스트와 트리의 기준을 6과 8로 잡은 것은 변경하는데 소요되는 비용을 줄이기 위함니다.

해시 버킷에 6개의 key-value 쌍이 들어있었다. 그리고 하나의 값이 추가되었다. 만약 기준이 6과 7이라면 자료구조를 연결리스트에서 트리로 변경해야 한다. 그러다 바로 하나의 값이 삭제된다면 다시 트리에서 연결리스트로 자료구조를 변경해야 한다. 각각 자료구조로 넘어가는 기준이 1 이라면 Switching 비용이 너무 많이 필요하게 된다. 그래서 2라는 여유를 남겨두고 기준을 잡는다. 따라서 6개에서 7개로 갈때는 연결리스트를 8개에서 7개로 갈때는 트리의 자료구조를 취하고 있다.


#### Open Address vs Separate Chaining

* Open Address 의 시간 복잡도

해시 테이블의 버킷의 길이를 `m`, key의 수를 `n`이라고 가정했을 때, 평균적으로 저장소에서 1개의 해시당 (n/m)개의 키가 들어있다. 이를 `α`라고 한다. `α`는 1보다 작거나 같다. 저장소 1개 버킷 당 1개의 값만 가지기 때문이다.

`n/m = α (α <= 1)`

삽입, 삭제, 탐색 모두 대상이 되는 해시를 찾아가는 과정에 따라 시간 복잡도가 계산된다. 해시 함수를 통해 얻은 해시가 비어있지 않으면 다음 버킷을 찾아가야 한다. (`O(1) ~ O(n)`)

따라서 비어있는 공간을 확보하는 것(= 저장소가 어느 정도 채워졌을 때 저장소의 사이즈를 늘려주는 것)이 필요하다.

* Separate Chaining 의 시간 복잡도

해시 테이블의 버킷의 길이를 `m`, key의 수를 `n`이라고 가정했을 때, 평균적으로 저장소에서 1개의 해시당 (n/m)개의 키가 들어있다. 이를 `α`라고 한다. 

`n/m = α (1개의 해시당 평균적으로 α개의 키가 들어있다.)`

삽입의 경우, 충돌이 일어났을 때, 해당 해시가 가진 연결리스트의 Head에 자료를 저장할 경우 `O(1)`의 시간 복잡도를 가진다. 만약 Tail에 자료를 저장할 경우, `O(α)`의 시간 복잡도를 가진다. 최악의 경우 `O(n)`의 시간 복잡도를 가진다.

삭제, 탐색의 경우, 해시의 연결리스트를 차례로 살펴보아야 하므로 `O(α)`이고, 최악의 경우 `O(n)`의 시간 복잡도를 가진다.



일단 두 방식 모두 최악의 경우에 `O(n)`이다. 하지만 `Open Address` 방식은 연속된 공간에 데이터를 저장하기 때문에 `Separate Chaining`에 비해 캐시 효율이 높다. 따라서 데이터의 개수가 충분히 적다면 `Open Address` 방식이 더 성능이 좋다. 하지만 `Open Address` 방식은 버킷을 계속해서 사용한다. 따라서 `Separate Chaining` 방식은 테이블의 확장을 보다 늦출 수 있다.

#### Open Address 장단점

* 장점

또다른 저장공간 없이 해시 테이블 내에서 데이터 저장 및 처리가 가능하다.

또다른 저장공간에서의 추가적인 작업이 없다.

* 단점

해시 함수의 성능에 전체 해시 테이블의 성능이 좌지우지된다.

데이터의 길이가 늘어나면 그에 해당하는 버킷을 마련해 두어야한다.


#### Separate Chaining 장단점

* 장점

한정된 버킷을 효율적으로 사용할 수 있다.

해시 함수를 선택하는 중요성이 상대적으로 적다.

상대적으로 적은 메모리를 사용한다. 미리 공간을 잡아 놓을 필요가 없다.

* 단점

한 해시에 자료들이 계속 연결된다면 검색 효율이 낮아진다. (쏠림현상)

외부 저장 공간을 사용한다. 외부 저장 공간 작업을 추가로 해야 한다.



#### 보조 해시 함수

보조 해시 함수(supplement hash function)의 목적은 key의 해시 값을 변형하여 해시 충돌 가능성을 줄이는 것이다. `Separate Chaining` 방식을 사용할 때 함께 사용되며 보조 해시 함수로 Worst Case에 가까워지는 경우를 줄일 수 있다.



### 해시 버킷 동적 확장(Resize)

해시 버킷의 개수가 적다면 메모리 사용을 아낄 수 있지만 해시 충돌로 인해 성능이 떨어진다. 그래서 HashMap은 key-value 쌍 데이터 개수가 일정 개수 이상이 되면 해시 버킷의 개수를 두 배로 늘린다. 해시 버킷 크기를 두 배로 확장하는 임계점은 현재 데이터 개수가 해시 버킷의 개수의 75%가 될 때이다. `0.75`라는 숫자는 load factor라고 불린다.

</br>

## Graph 

### 정점과 그 정점을 연결하는 간선의 집합

_cf) 트리는 사이클이 허용되지 않는 그래프이다.

### 그래프 관련된 용어

* 정점 (Vertex) : 객체
* 간선 (Edge) : 객체 간의 관계, 즉, 정점들을 연결하는 선
* 인접 정점 (adjacent vertex) : 간선에 의해 직접 연결된 정점
* 차수 (Degree) : 무방향 그래프에서 하나의 정점에 인접한 정점의 수
* 진입 차수 (in-degree) : 방향 그래프에서 외부에서 오는 간선의 수
* 진출 차수 (out-degree) : 방향 그래프에서 외부로 향하는 간선의 수
* 단순 경로 (Simple path) : 경로 중에서 반복되는 정점이 없는 경우
* 사이클 (cycle) : 단순 경로의 시작 정점과 종료 정점이 동일한 경우

### 그래프의 종류

* Undirected Graph
```
정점과 간선의 연결관계에 있어서 방향성이 없는 그래프
정점 A와 정점 B를 연결하는 간선은 (A, B)와 같이 정점의 쌍으로 표현된다. (A, B), (B, A) 는 동일
```

* Directed Graph
```
정점과 간선의 연결관계에 있어서 간선에 방향성이 존재하는 그래프
정점 A에서 정점 B로 향하는 간선은 <A, B>으로 표현된다. <A, B>, <B, A> 는 다름.
```

* Complete Graph
```
완전 그래프는 한 정점에서 모든 다른 정점과 연결되어 최대의 간선 수를 가지는 그래프
무방향 그래프에서의 최대 간선의 수 : n(n-1)/2
방향 그래프에서의 최대 간선의 수   : n(n-1)
```

* Weight Graph
```
정점을 연결하는 간선에 가중치를 할당하여 구성한 그래프
반대의 개념으로는 비가중치 그래프 (모든 간선의 가중치가 동일한 그래프)
```

* Sub Graph
```
원래의 그래프에서 일부의 정점이나 간선을 제외하여 만든 그래프
```


### 그래프를 구현하는 두 방법

#### 인접 행렬(adjacent matrix) : 정방 행렬을 사용하는 방법

해당하는 위치의 value 값을 통해서 정점 간의 연결 관계를 O(1) 으로 파악할 수 있다. 간선의 개수와는 무관하게 V^2의 공간 복잡도를 갖는다. Dense graph를 표현할 때 적절한 방법이다.

#### 인접 리스트(adjacent list) : 연결 리스트를 사용하는 방법

정점의 인접 리스트를 확인해봐야 하므로 정점 간 연결되어 있는지 확인하는데 오래 걸린다. O(E+V)의 공간 복잡도를 갖는다. Sparse graph를 표현할 때 적절한 방법이다.


### 그래프 탐색

#### 깊이 우선 탐색 (Depth First Search, DFS)

그래프 상에 존재하는 임의의 한 정점으로부터 연결되어 있는 한 정점으로만 나아간다라는 방법을 우선으로 탐색한다. 일단 연결된 정점으로 탐색하는 것이다. 연결할 수 있는 정점이 있을 때까지 계속 연결하다가 더이상 연결할 정점이 없으면 바로 전 단계의 정점으로 돌아가서 연결할 수 있는 정점이 있는지 살펴본다. 이를 위해서 `Stack`을 사용한다. 시간 복잡도는 `O(V+E)`이다. (정점의 수 + 간선의 수)

#### 너비 우선 탐색 (Breadth First Search, BFS)

그래프 상에 존재하는 임의의 한 정점으로부터 연결되어 있는 모든 정점으로 나아간다. 트리에서 Level Order Traversal 형식과 같다. 이를 위해서 `Queue`를 사용한다. 우선, 탐색을 시작하는 정점을 Queue에 넣는다.(enqueue) 그리고 Queue에 있는 정점을 하나씩 가져오는 dequeue를 하면서 dequeue하는 정점과 간선으로 연결되어 있는 정점들을 enqueue한다. 즉, 정점들을 방문한 순서대로 queue에 저장한다. 시간 복잡도는 `O(V+E)`이다. (정점의 수 + 간선의 수) BFS로 구한 경로는 최단 경로이다.


### Minimun Spanning Tree

그래프 G의 spanning tree 중 edge weight의 합이 최소인 spanning tree를 말한다. 여기서 말하는 spanning tree란 그래프의 G의 모든 정점이 cycle 없이 연결된 형태를 말한다. 

#### Kruskal Algorithm

간선 중에서 비용이 적은 순으로 정렬한다. 그리고 비용이 가장 작은 간선부터 추가하는데, 추가할 때 그래프에 cycle이 생기지 않는 경우에만 간선을 추가한다. spanning tree가 완성되면 모든 정점들이 연결된 상태로 종료된다.

##### cycle 생성 여부 판단

`union-find 알고리즘` 이용

그래프의 각 정점에 `set-id`라는 것을 추가적으로 부여한다. 그리고 초기화 과정에서 모두 1 ~ n 까지의 값으로 각각의 정점들을 초기화 한다. 여기서 0 은 어떠한 간선과 연결되지 않음을 의미한다. 그리고 연결할 때마다 `set-id`를 하나로 통일시키는데, 값을 동일한 `set-id`개수가 많은 `set-id` 값으로 통일시킨다.

##### Time Complexity

1. 간선의 비용을 기준으로 정렬 - O(E log E)
2. cycle 생성 여부를 검사하고 set-id를 통일 - O(E + V log V)

전체 시간 복잡도 : O(E log E)

#### Prim Algorithm

초기화 과정에서 한 개의 정점으로 이루어진 초기 그래프 A 를 구성한다. 그리고 그래프 A 내부에 있는 정점으로부터 외부에 있는 정점 사이의 간선을 연결하는데, 그 중 비용이 가장 작은 간선을 통해 연결되는 정점을 추가한다. 정점에 상관없이 간선의 비용을 기준으로 연결하는 것이다. 이렇게 연결된 정점은 그래프 A 에 포함된다. 위 과정을 반복하고 모든 정점들이 연결되면 종료한다.

##### Time Complexity

전체 시간 복잡도 : O(E log V)

</br>



